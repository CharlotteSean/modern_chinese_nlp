{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastai.text import LanguageModelLoader, LanguageModelData\n",
    "from fastai.core import T\n",
    "from fastai.rnn_reg import EmbeddingDropout\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = joblib.load(\"../data/tokens_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367208\n",
      "367208\n"
     ]
    }
   ],
   "source": [
    "# Filter out empty rows\n",
    "print(len(tokens))\n",
    "tokens = [x for x in tokens if x.shape[0] > 0]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tokens, val_tokens = train_test_split(tokens, test_size=0.2, random_state=9)\n",
    "val_tokens, tst_tokens = train_test_split(val_tokens, test_size=0.5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 97937703\n",
      "Unknown Percentage: 14.89 %\n"
     ]
    }
   ],
   "source": [
    "def get_voc_stats(tokens):\n",
    "    total_tokens = np.sum([x.shape[0] for x in tokens])\n",
    "    unks = np.sum([np.sum(x == 1) for x in tokens])\n",
    "    print(\"Total tokens: %d\\nUnknown Percentage: %.2f %%\" % (total_tokens, unks * 100 / total_tokens))\n",
    "get_voc_stats(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 100\n",
    "batch_size = 128\n",
    "n_tok = int(np.max([np.max(x) for x in tokens]) + 1)\n",
    "trn_loader = LanguageModelLoader(\n",
    "    np.concatenate(trn_tokens), batch_size, bptt)\n",
    "val_loader = LanguageModelLoader(\n",
    "    np.concatenate(val_tokens), batch_size, bptt)\n",
    "tst_loader = LanguageModelLoader(\n",
    "    np.concatenate(tst_tokens), batch_size, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 56521),\n",
       " (2, 29966),\n",
       " (3, 26778),\n",
       " (5, 19607),\n",
       " (4, 16459),\n",
       " (19, 8330),\n",
       " (6, 8020),\n",
       " (8, 6348),\n",
       " (10, 5468),\n",
       " (32, 4885)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tmp = []\n",
    "for i in range(10000):\n",
    "    for j in range(1, trn_tokens[i].shape[0]):\n",
    "        if trn_tokens[i][j] == 1:\n",
    "            tmp.append(trn_tokens[i][j-1])\n",
    "Counter(tmp).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 16458),\n",
       " (20, 9225),\n",
       " (6, 4395),\n",
       " (16, 1642),\n",
       " (23, 1119),\n",
       " (45, 1033),\n",
       " (109, 993),\n",
       " (36, 927),\n",
       " (29, 876),\n",
       " (95, 846)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tmp = []\n",
    "for i in range(10000):\n",
    "    for j in range(1, trn_tokens[i].shape[0]-1):\n",
    "        if trn_tokens[i][j] == 4:\n",
    "            tmp.append(trn_tokens[i][j+1])\n",
    "Counter(tmp).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = joblib.load(\"../data/mapping_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = ['<pad>'] + ['<unk>'] *  n_tok\n",
    "for k, v in mapping.items():\n",
    "    itos[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/cache/lm_word/\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "model_data = LanguageModelData(\n",
    "    path, pad_idx=0, n_tok=n_tok, trn_dl=trn_loader, val_dl=val_loader, test_dl=tst_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### QRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drops = np.array([0.05, 0.1, 0.05, 0, 0.1])\n",
    "learner = model_data.get_model(\n",
    "    partial(Adam, betas=(0.8, 0.999)),\n",
    "    emb_sz=300, n_hid=500, n_layers=4,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2],\n",
    "    dropoute=drops[3], dropouth=drops[4], qrnn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.clip = 25.\n",
    "learner.lr_find(start_lr=1e-5, end_lr=1, linear=False)\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = 2e-3\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = 5e-4\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save(\"lm_qrnn\")\n",
    "learner.save_encoder(\"lm_qrnn_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load(\"lm_qrnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.1, 0.1, 0.05, 0, 0.1])\n",
    "learner = model_data.get_model(\n",
    "    partial(Adam, betas=(0.7, 0.99)),\n",
    "    emb_sz=300, n_hid=500, n_layers=3,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2],\n",
    "    dropoute=drops[3], dropouth=drops[4], qrnn=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f196c0840f704eada446dd0b6cd13991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5362/6120 [18:27<02:36,  4.84it/s, loss=18.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.clip = 10.\n",
    "learner.lr_find(start_lr=1e-5, end_lr=1, linear=False)\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aa146244da4443b527c51198c02803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.599382   4.512122  \n",
      "    1      4.300838   4.19133                                 \n",
      "    2      4.229062   4.113047                                \n",
      "    3      4.17813    4.055418                                \n",
      "    4      4.14       4.010401                                \n",
      "    5      4.110208   3.978438                                \n",
      "    6      4.084675   3.953387                                \n",
      "    7      4.058134   3.931805                                \n",
      "    8      4.045278   3.91166                                 \n",
      "    9      4.017105   3.895606                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.895605748477801]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs = 3e-3\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"lm_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bdf50420964292b37dc24c9387dc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.022002   3.899044  \n",
      "    1      4.034041   3.905991                                \n",
      "    2      4.043982   3.913612                                \n",
      "    3      4.046286   3.913167                                \n",
      "    4      4.044897   3.909215                                \n",
      " 34%|███▍      | 2071/6120 [07:17<14:14,  4.74it/s, loss=4.03]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d09f60b6045e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_wd_sched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs = 1e-3\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"lm_lstm\")\n",
    "learner.save_encoder(\"lm_lstm_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tons of memory...\n",
    "# pred, targ = learner.predict_with_targs(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_iter = iter(trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(tmp_iter)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load(\"lm_lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(13003, 300, padding_idx=0)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(13003, 300, padding_idx=0)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(300, 500)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(500, 500)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(500, 300)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout()\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout()\n",
       "      (1): LockedDropout()\n",
       "      (2): LockedDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=300, out_features=13003, bias=False)\n",
       "    (dropout): LockedDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Character Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/46/c6f9179f73b818d5827202ad1c4a94e371a29473b7f043b736b4dab6b8cd/jieba-0.39.zip (7.3MB)\n",
      "\u001b[K    100% |################################| 7.3MB 204kB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Running setup.py bdist_wheel for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/docker/.cache/pip/wheels/c9/c7/63/a9ec0322ccc7c365fd51e475942a82395807186e94f0522243\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.39\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[298, 7, 148, 7074, 226, 2, 42, 870, 450, 427, 3231, 25, 154, 11036, 3299]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = \"德国 是 世界 大国 之一 ， 其 国内 生产 总 值 以 国际 汇率 计\"\n",
    "tokens = list(map(lambda x: mapping.get(x, 1), texts.split(\" \")))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 13003])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>德国</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>是</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>的</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>世界</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>最</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>大国</td>\n",
       "      <td>上</td>\n",
       "      <td>最</td>\n",
       "      <td>第二</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>之一</td>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>之一</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>，</td>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>；</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>其</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>而</td>\n",
       "      <td>仅次于</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>国内</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>经济</td>\n",
       "      <td>主要</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>生产</td>\n",
       "      <td>生产总值</td>\n",
       "      <td>经济</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>总</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>总量</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>值</td>\n",
       "      <td>金额</td>\n",
       "      <td>投资</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>以</td>\n",
       "      <td>为</td>\n",
       "      <td>达</td>\n",
       "      <td>约</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>国际</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>约</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>汇率</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>货币</td>\n",
       "      <td>上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>计</td>\n",
       "      <td>为</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>计算</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>为</td>\n",
       "      <td>，</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig pred_1 pred_2 pred_3\n",
       "0    德国                     \n",
       "1     是  <unk>      的      、\n",
       "2    世界  <unk>      最     世界\n",
       "3    大国      上      最     第二\n",
       "4    之一      。      ，     之一\n",
       "5     ，      。      ，      ；\n",
       "6     其  <unk>      而    仅次于\n",
       "7    国内  <unk>     经济     主要\n",
       "8    生产   生产总值     经济  <unk>\n",
       "9     总      的  <unk>     总量\n",
       "10    值     金额     投资  <unk>\n",
       "11    以      为      达      约\n",
       "12   国际  <unk>      1      约\n",
       "13   汇率  <unk>     货币      上\n",
       "14    计      为  <unk>     计算\n",
       "15           为      ，  <unk>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = np.argsort(logits.data.cpu().numpy(), 1)\n",
    "preds = []\n",
    "for i in range(1, 4):\n",
    "      preds.append(list(map(lambda x: itos[x], sorted_idx[:, -i])))\n",
    "# preds = list(map(lambda x: itos[x], np.argmax(logits.data.cpu().numpy(), 1)))\n",
    "pd.DataFrame({\"orig\": list(texts.split(\" \")) + [\" \"], \n",
    "              \"pred_1\": [\"\"] + preds[0], \"pred_2\": [\"\"] + preds[1], \"pred_3\": [\"\"] + preds[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(texts):\n",
    "    learner.model[0].reset()\n",
    "    tokens = list(map(lambda x: mapping.get(x, 1), texts))\n",
    "    logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "    sorted_idx = np.argsort(logits.data.cpu().numpy(), 1)\n",
    "    preds = []\n",
    "    for i in range(1, 4):\n",
    "          preds.append(list(map(lambda x: itos[x], sorted_idx[:, -i])))\n",
    "    # preds = list(map(lambda x: itos[x], np.argmax(logits.data.cpu().numpy(), 1)))\n",
    "    return pd.DataFrame({\"orig\": [x for x in texts] + [\" \"], \n",
    "                  \"pred_1\": [\"\"] + preds[0], \"pred_2\": [\"\"] + preds[1], \"pred_3\": [\"\"] + preds[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>现代</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>中国</td>\n",
       "      <td>美国</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>印刷</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>的</td>\n",
       "      <td>社会</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>媒体</td>\n",
       "      <td>中</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>，</td>\n",
       "      <td>中</td>\n",
       "      <td>上</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>卡通</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>并</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>是</td>\n",
       "      <td>频道</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>杂志</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>一种</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>一</td>\n",
       "      <td>由</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>通常</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>有</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>幽默</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>一</td>\n",
       "      <td>两</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>色</td>\n",
       "      <td>的</td>\n",
       "      <td>、</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>的</td>\n",
       "      <td>，</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig pred_1 pred_2 pred_3\n",
       "0     在                     \n",
       "1    现代  <unk>     中国     美国\n",
       "2    印刷  <unk>      的     社会\n",
       "3    媒体      中      的  <unk>\n",
       "4     ，      中      上      的\n",
       "5    卡通  <unk>      并      在\n",
       "6     是     频道  <unk>     杂志\n",
       "7    一种  <unk>      一      由\n",
       "8    通常      的  <unk>      ，\n",
       "9     有      的  <unk>      在\n",
       "10   幽默  <unk>      一      两\n",
       "11    色      的      、  <unk>\n",
       "12           的      ，      、"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(list(jieba.cut(\"在现代印刷媒体，卡通是一种通常有幽默色\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>对</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中国</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>此</td>\n",
       "      <td>其</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>与</td>\n",
       "      <td>大陆</td>\n",
       "      <td>的</td>\n",
       "      <td>人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>南洋</td>\n",
       "      <td>中国</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>日本</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>发动</td>\n",
       "      <td>的</td>\n",
       "      <td>地区</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>全面</td>\n",
       "      <td>的</td>\n",
       "      <td>战争</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>的</td>\n",
       "      <td>战争</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>战争</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>战争</td>\n",
       "      <td>侵略</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>。</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1990</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td></td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>年代</td>\n",
       "      <td>年代</td>\n",
       "      <td>至</td>\n",
       "      <td>－</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>，</td>\n",
       "      <td>，</td>\n",
       "      <td>初</td>\n",
       "      <td>中期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>中</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>中国</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>英</td>\n",
       "      <td>美</td>\n",
       "      <td>日</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orig pred_1 pred_2 pred_3\n",
       "0      对                     \n",
       "1     中国  <unk>      此      其\n",
       "2      与     大陆      的      人\n",
       "3     南洋     中国  <unk>     日本\n",
       "4     发动      的     地区  <unk>\n",
       "5     全面      的     战争  <unk>\n",
       "6      的     战争      的  <unk>\n",
       "7     战争  <unk>     战争     侵略\n",
       "8      。      ，      。      的\n",
       "9   1990  <unk>             在\n",
       "10    年代     年代      至      －\n",
       "11     ，      ，      初     中期\n",
       "12     中  <unk>     中国      在\n",
       "13            英      美      日"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(list(jieba.cut(\"对中国与南洋发动全面的战争。1990年代，中\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0849  0.04522 0.04519] 0.0020851453\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国\n",
      "[0.09918 0.08674 0.03713] 0.004072963\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之\n",
      "[0.12832 0.02331 0.01787] 0.00030839004\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器\n",
      "[0.06282 0.049   0.02834] 0.017302074\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也\n",
      "[0.09091 0.04467 0.03473] 0.03472741\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都\n",
      "[0.11333 0.08056 0.03986] 0.003928228\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已\n",
      "[0.11237 0.04534 0.04051] 0.04050917\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有\n",
      "[0.11852 0.0384  0.03166] 0.00021041263\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代\n",
      "[0.31203 0.19704 0.09372] 0.3120301\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。\n",
      "[0.21283 0.11078 0.04112] 0.21283479\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。\n",
      "[0.3737  0.03779 0.03099] 0.0029591594\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年\n",
      "[0.14677 0.06127 0.06048] 0.1467675\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，\n",
      "[0.41788 0.02925 0.02721] 0.00022997423\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据\n",
      "[0.26969 0.17865 0.03119] 9.514152e-06\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年\n",
      "[0.13684 0.07112 0.0663 ] 0.0072263614\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第\n",
      "[0.24461 0.03998 0.03587] 0.01127346\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16\n",
      "[0.60511 0.14896 0.04602] 0.6051103\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届\n",
      "[0.16728 0.09187 0.06486] 0.06485701\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港\n",
      "[0.13468 0.11429 0.09955] 0.047356937\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视\n",
      "[0.16143 0.16125 0.0874 ] 0.07823605\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络\n",
      "[0.11496 0.08336 0.04273] 6.6866687e-07\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络同乡\n",
      "[0.53441 0.14379 0.06709] 0.5344089\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络同乡会\n",
      "[0.08786 0.07545 0.023  ] 0.00036108555\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络同乡会将\n",
      "[0.18614 0.13745 0.04483] 0.00025563093\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络同乡会将出席\n",
      "[0.17934 0.11596 0.06633] 0.00024286388\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，各国之武器也都已有取代。2011年，依据1975年第16届香港电视网络同乡会将出席作品\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_tokens(texts, seg=True):\n",
    "    if seg:\n",
    "        texts = list(jieba.cut(texts))\n",
    "    return list(map(lambda x: mapping.get(x, 1), texts))\n",
    "\n",
    "def generate_text(tokens,N=25):    \n",
    "    preds = []          \n",
    "    for i in range(N):   \n",
    "        learner.model[0].reset()          \n",
    "        logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "        probs = F.softmax(logits).data.cpu().numpy()[-1, :]\n",
    "        candidates = np.argsort(probs)[::-1]\n",
    "        while True:\n",
    "            candidate = np.random.choice(candidates, p=probs[candidates])\n",
    "            if candidate > 1:\n",
    "                print(probs[candidates][:3], probs[candidate])\n",
    "                preds.append(candidate)\n",
    "                break\n",
    "        # for candidate in candidates:\n",
    "        #     if candidate > 1 and ord(itos[candidate]) > 255 and (random.random() < probs[candidate] or probs[candidate] < 0.2):\n",
    "        #         print(probs[candidate])\n",
    "        #         preds.append(candidate)\n",
    "        #         break\n",
    "        # tokens  = [preds[-1]]# \n",
    "        tokens.append(preds[-1])\n",
    "        # tokens = [:1]\n",
    "        print(\"\".join([itos[x] for x in tokens])) \n",
    "    \n",
    "generate_text(get_tokens(\"德国是世界大国之一，其国内生产总值以国际汇率为主，\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07484 0.05312 0.04248] 0.00071701215\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年\n",
      "[0.29586 0.10333 0.10185] 0.015437807\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入\n",
      "[0.21442 0.1808  0.10822] 0.00040535812\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700\n",
      "[0.36304 0.12111 0.10409] 0.072563\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,\n",
      "[0.65283 0.29717 0.01147] 0.65283036\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000\n",
      "[0.58227 0.15969 0.08407] 0.58227104\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元\n",
      "[0.59681 0.30766 0.031  ] 0.5968141\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。\n",
      "[0.24557 0.0916  0.04402] 0.0058658537\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据\n",
      "[0.14143 0.05549 0.05085] 0.016316457\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界\n",
      "[0.21682 0.13947 0.07855] 0.21682173\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行\n",
      "[0.22654 0.09074 0.04611] 0.006457782\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站\n",
      "[0.20531 0.11473 0.09224] 0.20530608\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的\n",
      "[0.38944 0.09377 0.0578 ] 0.3894443\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计\n",
      "[0.67985 0.13705 0.04179] 0.006931866\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名\n",
      "[0.92938 0.00663 0.00637] 0.9293801\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，\n",
      "[0.18083 0.04372 0.03757] 0.0015050073\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦\n",
      "[0.14126 0.09683 0.09142] 0.0068267267\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府\n",
      "[0.14256 0.07843 0.04007] 0.0055860584\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供\n",
      "[0.25225 0.15171 0.09859] 0.007960834\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量\n",
      "[0.2314  0.10516 0.06799] 1.9268604e-05\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群\n",
      "[0.08152 0.05659 0.04726] 0.00015450607\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群传媒\n",
      "[0.15153 0.09072 0.05868] 0.0038613616\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群传媒中\n",
      "[0.55957 0.06826 0.04641] 0.0020511816\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群传媒中占\n",
      "[0.24584 0.07514 0.0346 ] 0.0019760672\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群传媒中占相当\n",
      "[0.23312 0.1466  0.10767] 0.23312141\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，年收入700,000美元。根据世界银行网站的统计排名，丹麦政府提供大量社群传媒中占相当比例\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"德国 是 世界 大国 之一 ， 其 国内 生产 总 值 以 国际 汇率 为主 ，\".split(\" \"), seg=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57148 0.10214 0.08893] 0.10213592\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，\n",
      "[0.12241 0.04842 0.02696] 0.00512519\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被\n",
      "[0.16758 0.11191 0.06359] 0.02920835\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人\n",
      "[0.27767 0.09662 0.06675] 0.0006173651\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑\n",
      "[0.20633 0.08822 0.06203] 0.008166621\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，\n",
      "[0.14941 0.03693 0.03217] 0.002003036\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指\n",
      "[0.24453 0.09932 0.02587] 0.005567843\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为\n",
      "[0.31994 0.05797 0.03811] 0.0013306263\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时\n",
      "[0.22526 0.11243 0.0357 ] 0.00038319558\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的\n",
      "[0.22117 0.07134 0.01125] 0.00091244903\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他\n",
      "[0.17724 0.03044 0.0282 ] 0.0008020848\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「\n",
      "[0.38756 0.00886 0.00842] 0.000650396\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们\n",
      "[0.32084 0.17149 0.1125 ] 0.17148939\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的\n",
      "[0.36169 0.01851 0.01332] 0.00017412976\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像\n",
      "[0.38612 0.11171 0.0904 ] 0.00018850392\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/\n",
      "[0.10611 0.01873 0.01766] 0.00054056145\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理\n",
      "[0.11135 0.07953 0.05507] 0.010589225\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式\n",
      "[0.57668 0.10968 0.07248] 0.57667893\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」\n",
      "[0.4858  0.23323 0.05428] 0.23323293\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，\n",
      "[0.06557 0.05952 0.03407] 0.01981238\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在\n",
      "[0.13992 0.01295 0.01277] 0.0036469845\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他\n",
      "[0.36201 0.05351 0.03515] 0.3620107\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的\n",
      "[0.12995 0.10031 0.04044] 0.00022794218\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签\n",
      "[0.259   0.15516 0.11674] 0.00017568417\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签宣传\n",
      "[0.18719 0.10796 0.04519] 0.010544763\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签宣传方面\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"在现代印刷媒体，卡通是一种通常有幽默色\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11664 0.0809  0.063  ] 0.013735259\n",
      "在现代印刷媒体，第21\n",
      "[0.1503  0.12699 0.06979] 0.15030143\n",
      "在现代印刷媒体，第21届\n",
      "[0.29316 0.04064 0.02644] 0.0003290113\n",
      "在现代印刷媒体，第21届蒙特利尔\n",
      "[0.27749 0.25952 0.04082] 0.00036318615\n",
      "在现代印刷媒体，第21届蒙特利尔传媒\n",
      "[0.15316 0.14406 0.12543] 0.004984978\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界\n",
      "[0.58364 0.06818 0.0337 ] 0.58364475\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会\n",
      "[0.1648  0.09174 0.06011] 0.005921887\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式\n",
      "[0.09121 0.06231 0.05032] 0.00029816577\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供\n",
      "[0.24674 0.11326 0.05285] 0.0031860475\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用\n",
      "[0.3879  0.13697 0.09953] 0.38790128\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。\n",
      "[0.37138 0.09383 0.04414] 0.01921569\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《\n",
      "[0.8653  0.03373 0.00391] 0.00019770922\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪\n",
      "[0.71019 0.09051 0.01247] 0.00024495873\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八\n",
      "[0.17896 0.13515 0.074  ] 0.04536766\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年\n",
      "[0.51304 0.11689 0.02403] 4.435249e-06\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客\n",
      "[0.4205  0.04554 0.02305] 0.00033277567\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货\n",
      "[0.27485 0.13842 0.01394] 0.0002715393\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版\n",
      "[0.83644 0.04947 0.01061] 0.8364366\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》\n",
      "[0.08444 0.07868 0.07087] 0.08443941\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于\n",
      "[0.06968 0.06828 0.05944] 0.050564583\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年\n",
      "[0.08757 0.08671 0.08016] 0.017276105\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年在\n",
      "[0.17855 0.08828 0.06839] 0.019549878\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年在纽约\n",
      "[0.21517 0.13286 0.04714] 0.004199498\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年在纽约卖\n",
      "[0.74467 0.06994 0.03113] 0.006100572\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年在纽约卖至\n",
      "[0.16441 0.12278 0.04084] 0.013943902\n",
      "在现代印刷媒体，第21届蒙特利尔传媒世界博览会正式提供使用。《世纪十八年客货中文版》于2012年在纽约卖至《\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"在现代印刷媒体，第\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21993 0.11504 0.06094] 0.0031887044\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后\n",
      "[0.43218 0.07533 0.03038] 0.030377774\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本\n",
      "[0.06742 0.0578  0.05238] 0.052381463\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府\n",
      "[0.06934 0.06929 0.06898] 0.009819492\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和\n",
      "[0.15521 0.12348 0.07315] 0.0050978772\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体\n",
      "[0.07115 0.05296 0.05177] 0.0032551514\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有\n",
      "[0.12189 0.11431 0.05374] 0.002374734\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突\n",
      "[0.58989 0.10965 0.07273] 0.1096453\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。\n",
      "[0.1693  0.0792  0.05049] 0.00032899523\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导\n",
      "[0.1343  0.103   0.07515] 0.13429593\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称\n",
      "[0.50977 0.07816 0.06281] 0.50976896\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，\n",
      "[0.21276 0.09568 0.05249] 0.00014371001\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前\n",
      "[0.12569 0.12374 0.0835 ] 0.0036918137\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将\n",
      "[0.20202 0.03102 0.02861] 6.8865455e-05\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨\n",
      "[0.23845 0.12039 0.03282] 0.00025145832\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判\n",
      "[0.25974 0.08502 0.03404] 0.0011072743\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入\n",
      "[0.20649 0.03365 0.03039] 0.0023282075\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三\n",
      "[0.23106 0.13269 0.10196] 0.08269343\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国\n",
      "[0.15874 0.06885 0.03173] 0.00046338578\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十\n",
      "[0.63647 0.12101 0.1009 ] 0.6364737\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大\n",
      "[0.18894 0.0365  0.03634] 0.0011145439\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大司法\n",
      "[0.20996 0.13177 0.08818] 0.004233392\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大司法运动\n",
      "[0.21648 0.14375 0.11561] 0.21648084\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大司法运动的\n",
      "[0.15339 0.01955 0.01376] 0.0002487568\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大司法运动的局面\n",
      "[0.50413 0.22585 0.03389] 0.019261198\n",
      "日本后来成为<unk>的<unk>之一，对中国与南洋发动全面的战争。此后日本政府和媒体有冲突。报导称，先前将哈尔滨审判列入三国十大司法运动的局面是\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"日本后来成为第二次世界大战的轴心国之一，对中国与南洋发动全面的战争。\"))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39694 0.36526 0.02658] 0.36526316\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代\n",
      "[0.41169 0.13265 0.10885] 0.41168737\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的\n",
      "[0.40085 0.02    0.01966] 0.0010712872\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古\n",
      "[0.39935 0.11373 0.03979] 0.11373325\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马\n",
      "[0.19187 0.1613  0.11238] 2.6517653e-05\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻\n",
      "[0.22348 0.06622 0.05206] 0.040794715\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日\n",
      "[0.29213 0.15053 0.05442] 0.2921269\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节\n",
      "[0.28275 0.22185 0.18266] 0.22185424\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。\n",
      "[0.13797 0.12764 0.0648 ] 0.003236326\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《\n",
      "[0.90108 0.02141 0.01096] 0.0004479174\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧\n",
      "[0.78727 0.00918 0.00742] 0.003789357\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家\n",
      "[0.37808 0.03831 0.0272 ] 0.027202351\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的\n",
      "[0.29519 0.02051 0.0159 ] 0.0014507378\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「\n",
      "[0.40816 0.02301 0.02279] 0.0066846404\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治\n",
      "[0.39292 0.02632 0.02462] 0.0011975212\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向\n",
      "[0.26415 0.18977 0.0944 ] 0.010946631\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：\n",
      "[0.46695 0.01602 0.01567] 7.561999e-05\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派\n",
      "[0.33632 0.07344 0.04282] 0.0428201\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人\n",
      "[0.22258 0.06364 0.04776] 0.028653556\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之\n",
      "[0.19548 0.12723 0.02798] 0.0016101728\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权\n",
      "[0.65833 0.11776 0.0393 ] 0.6583264\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权》\n",
      "[0.07146 0.06371 0.05806] 0.07145881\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权》中\n",
      "[0.2496  0.11799 0.0742 ] 0.0020781218\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权》中《\n",
      "[0.91736 0.0116  0.00916] 5.7746853e-05\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权》中《最高\n",
      "[0.21753 0.12886 0.0768 ] 0.21753132\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的<unk>体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的<unk>年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国时代的古罗马驻日使节。《旧国家的「政治走向：派人之政权》中《最高人民\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"传说日本于公元前660年2月11日建国，在公元4世纪出现首个统一政权，并于大化改新中确立了天皇的中央集权体制\"\n",
    "                         \"。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等从汉文化引进的事物，开始派生出今日为人所知的文化基\"\n",
    "                         \"础。12世纪后的六百年间，日本由武家阶级创建的数个幕府及军事强人政权实际掌权，期间包括了政治纷乱的南北朝与\"\n",
    "                         \"战国\"))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11416 0.08513 0.06321] 0.063211806\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都\n",
      "[0.16304 0.07353 0.05841] 0.048795726\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会\n",
      "[0.10815 0.10097 0.0361 ] 0.0006043374\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用\n",
      "[0.22446 0.12441 0.06509] 0.0023408516\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着\n",
      "[0.19655 0.0555  0.02482] 0.00933928\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“\n",
      "[0.38922 0.01607 0.0096 ] 0.00020508024\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高\n",
      "[0.1931  0.06098 0.04935] 0.0009540835\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人\n",
      "[0.73195 0.04881 0.03898] 0.7319476\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”\n",
      "[0.22078 0.178   0.1072 ] 0.10719734\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来\n",
      "[0.16135 0.03035 0.02646] 0.0003229139\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理\n",
      "[0.69339 0.1146  0.02897] 0.6933901\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，\n",
      "[0.17929 0.08461 0.0452 ] 0.016904753\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那\n",
      "[0.31266 0.08003 0.0438 ] 0.0008741273\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件\n",
      "[0.74085 0.19373 0.01411] 0.74085003\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事\n",
      "[0.1335  0.07655 0.06794] 0.011342538\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是\n",
      "[0.12016 0.0911  0.02539] 0.00017657368\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行\n",
      "[0.10288 0.02608 0.0254 ] 0.00065377005\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同\n",
      "[0.17422 0.1605  0.09226] 0.17422174\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责\n",
      "[0.43209 0.28313 0.17255] 0.43209422\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。\n",
      "[0.19475 0.0858  0.03507] 0.035067257\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“\n",
      "[0.214   0.04359 0.03528] 2.431228e-05\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“发表\n",
      "[0.07588 0.07462 0.04684] 0.00043178297\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“发表已\n",
      "[0.08453 0.06147 0.04289] 0.00012215778\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“发表已投降\n",
      "[0.59592 0.04163 0.01836] 0.5959189\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“发表已投降的\n",
      "[0.16481 0.0373  0.03062] 0.00017595392\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富都会用着“最高负责人”来审理，那件事就是履行共同职责。“发表已投降的杰出\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"特朗普政府以为加征关税会令中国屈服，这种策略肯定会适得其反。如果就业和财富\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58688 0.21864 0.06204] 0.21864145\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，\n",
      "[0.08225 0.03587 0.03177] 0.035866797\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也\n",
      "[0.513   0.08835 0.02651] 0.019834323\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此\n",
      "[0.11471 0.05706 0.04159] 0.0018013393\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得\n",
      "[0.45392 0.09671 0.09276] 0.4539174\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了\n",
      "[0.15686 0.12947 0.03942] 0.0051760557\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数\n",
      "[0.36104 0.11248 0.02504] 0.00020658024\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表\n",
      "[0.42557 0.13217 0.05996] 0.00026125772\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民\n",
      "[0.71088 0.05353 0.03315] 0.7108811\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的\n",
      "[0.30404 0.15879 0.05446] 0.15878811\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同\n",
      "[0.70599 0.20705 0.03779] 0.70599043\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。\n",
      "[0.25067 0.09793 0.03953] 0.25067285\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。\n",
      "[0.37804 0.03957 0.03647] 0.0014364156\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因\n",
      "[0.25755 0.03717 0.03537] 0.0013621522\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏\n",
      "[0.10769 0.08022 0.0513 ] 0.00019819176\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂\n",
      "[0.38757 0.19812 0.12047] 0.38757402\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，\n",
      "[0.13867 0.10605 0.05339] 0.010496704\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情\n",
      "[0.0951  0.03086 0.02835] 0.0036544949\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦\n",
      "[0.11076 0.0584  0.04928] 0.012252931\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到\n",
      "[0.07595 0.06967 0.05402] 0.054023355\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家\n",
      "[0.36285 0.05932 0.05427] 0.0008375057\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家追求\n",
      "[0.40791 0.31902 0.06168] 0.40791163\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家追求，\n",
      "[0.0698  0.06249 0.05685] 0.0026632564\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家追求，该\n",
      "[0.5203  0.14279 0.04595] 0.520305\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家追求，该游戏\n",
      "[0.11532 0.0515  0.03686] 7.740277e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，也因此赢得了无数代表公民的认同。因游戏复杂，剧情亦受到玩家追求，该游戏修正\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Instagram上备受欢迎的拍照地\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47741 0.40768 0.0114 ] 0.40768224\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，\n",
      "[0.08954 0.03386 0.03175] 0.033860967\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而\n",
      "[0.24851 0.05131 0.03842] 1.850885e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原\n",
      "[0.15722 0.1034  0.03688] 0.035690267\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则\n",
      "[0.33877 0.05513 0.04813] 0.0003147805\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往\n",
      "[0.17336 0.07788 0.05038] 0.030987084\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后\n",
      "[0.22443 0.02655 0.02579] 0.010277393\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展\n",
      "[0.31932 0.2974  0.04057] 0.31931937\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，\n",
      "[0.09547 0.04247 0.03163] 0.0052554267\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且\n",
      "[0.14168 0.05068 0.03665] 0.050678797\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在\n",
      "[0.19516 0.05805 0.00672] 0.058054496\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港\n",
      "[0.1225  0.09928 0.03835] 0.038351897\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、\n",
      "[0.43312 0.16496 0.08294] 0.16496448\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港\n",
      "[0.47606 0.12711 0.10589] 0.12711266\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及\n",
      "[0.26719 0.19248 0.10177] 0.2671916\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门\n",
      "[0.18384 0.17759 0.06197] 0.17758514\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等\n",
      "[0.68942 0.04957 0.0419 ] 0.6894157\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地\n",
      "[0.14759 0.10883 0.10431] 0.0006684094\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往\n",
      "[0.18561 0.12273 0.08054] 0.06455228\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是\n",
      "[0.24705 0.0312  0.02173] 8.424545e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正\n",
      "[0.20782 0.11783 0.03378] 0.00058523525\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正处\n",
      "[0.17132 0.13976 0.0534 ] 0.0012468708\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正处大型\n",
      "[0.22311 0.18865 0.04455] 0.18864667\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正处大型的\n",
      "[0.29945 0.03399 0.03256] 0.033988692\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正处大型的城市\n",
      "[0.49173 0.24703 0.04582] 0.4917303\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象，而平原则往后发展，而且在香港、香港及澳门等地往往是正处大型的城市。\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，\"\n",
    "                         \"呈现出一个与天际线中的香港不同的景象\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22934 0.12194 0.10099] 0.00017378815\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将\n",
      "[0.13531 0.1033  0.02304] 0.009363478\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之\n",
      "[0.26113 0.01951 0.01359] 0.001994004\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购\n",
      "[0.37535 0.24325 0.15594] 0.37534723\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的\n",
      "[0.21455 0.04711 0.04096] 0.047114447\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一\n",
      "[0.17173 0.09437 0.0859 ] 0.17172615\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分\n",
      "[0.70053 0.27097 0.01072] 0.7005291\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。\n",
      "[0.28008 0.11248 0.03315] 0.0045659863\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年\n",
      "[0.19158 0.06081 0.05345] 0.0524147\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月\n",
      "[0.26277 0.03356 0.02305] 0.26276892\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，\n",
      "[0.32059 0.08894 0.01864] 0.000909049\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府\n",
      "[0.08359 0.07386 0.06535] 0.0009491466\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算\n",
      "[0.12336 0.09015 0.06686] 0.00090663374\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用\n",
      "[0.4966  0.04159 0.01703] 0.009747753\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原\n",
      "[0.26799 0.2452  0.05623] 0.24520016\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住\n",
      "[0.40282 0.18746 0.11544] 0.18745883\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族\n",
      "[0.13586 0.10229 0.0365 ] 0.0024079427\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、\n",
      "[0.27698 0.02176 0.01908] 0.00017590415\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化\n",
      "[0.15031 0.0533  0.03643] 0.0024999874\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成\n",
      "[0.28052 0.02224 0.02198] 0.0024216368\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来\n",
      "[0.4308  0.07471 0.01933] 0.43079856\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来的\n",
      "[0.28404 0.06051 0.02252] 0.0026687223\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来的华人\n",
      "[0.14148 0.05825 0.04504] 0.0072283964\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来的华人土地\n",
      "[0.36216 0.06502 0.06492] 0.3621602\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来的华人土地，\n",
      "[0.0762  0.06418 0.05725] 0.0017958643\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>将之收购的一部分。2013年11月，港府打算借用原住民族、简化成原来的华人土地，不\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Insta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
