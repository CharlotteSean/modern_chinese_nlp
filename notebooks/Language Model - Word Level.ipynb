{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastai.text import LanguageModelLoader, LanguageModelData\n",
    "from fastai.core import T\n",
    "from fastai.rnn_reg import EmbeddingDropout\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = joblib.load(\"../data/tokens_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367208\n",
      "367208\n"
     ]
    }
   ],
   "source": [
    "# Filter out empty rows\n",
    "print(len(tokens))\n",
    "tokens = [x for x in tokens if x.shape[0] > 0]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tokens, val_tokens = train_test_split(tokens, test_size=0.2, random_state=9)\n",
    "val_tokens, tst_tokens = train_test_split(val_tokens, test_size=0.5, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 97937703\n",
      "Unknown Percentage: 11.25 %\n"
     ]
    }
   ],
   "source": [
    "def get_voc_stats(tokens):\n",
    "    total_tokens = np.sum([x.shape[0] for x in tokens])\n",
    "    unks = np.sum([np.sum(x == 1) for x in tokens])\n",
    "    print(\"Total tokens: %d\\nUnknown Percentage: %.2f %%\" % (total_tokens, unks * 100 / total_tokens))\n",
    "get_voc_stats(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 50\n",
    "batch_size = 64\n",
    "n_tok = int(np.max([np.max(x) for x in tokens]) + 1)\n",
    "trn_loader = LanguageModelLoader(\n",
    "    np.concatenate(trn_tokens), batch_size, bptt)\n",
    "val_loader = LanguageModelLoader(\n",
    "    np.concatenate(val_tokens), batch_size, bptt)\n",
    "tst_loader = LanguageModelLoader(\n",
    "    np.concatenate(tst_tokens), batch_size, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 35707),\n",
       " (2, 23571),\n",
       " (3, 19016),\n",
       " (5, 16390),\n",
       " (4, 13112),\n",
       " (19, 7755),\n",
       " (6, 5851),\n",
       " (8, 4863),\n",
       " (10, 4395),\n",
       " (32, 4220)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tmp = []\n",
    "for i in range(10000):\n",
    "    for j in range(1, trn_tokens[i].shape[0]):\n",
    "        if trn_tokens[i][j] == 1:\n",
    "            tmp.append(trn_tokens[i][j-1])\n",
    "Counter(tmp).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 13111),\n",
       " (20, 9225),\n",
       " (6, 4395),\n",
       " (16, 1642),\n",
       " (23, 1119),\n",
       " (45, 1033),\n",
       " (109, 993),\n",
       " (36, 927),\n",
       " (29, 876),\n",
       " (95, 846)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tmp = []\n",
    "for i in range(10000):\n",
    "    for j in range(1, trn_tokens[i].shape[0]-1):\n",
    "        if trn_tokens[i][j] == 4:\n",
    "            tmp.append(trn_tokens[i][j+1])\n",
    "Counter(tmp).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = joblib.load(\"../data/mapping_word.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = ['<pad>'] + ['<unk>'] *  n_tok\n",
    "for k, v in mapping.items():\n",
    "    itos[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/cache/lm_word/\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "model_data = LanguageModelData(\n",
    "    path, pad_idx=0, n_tok=n_tok, trn_dl=trn_loader, val_dl=val_loader, test_dl=tst_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### QRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drops = np.array([0.05, 0.1, 0.05, 0, 0.1])\n",
    "learner = model_data.get_model(\n",
    "    partial(Adam, betas=(0.8, 0.999)),\n",
    "    emb_sz=300, n_hid=500, n_layers=4,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2],\n",
    "    dropoute=drops[3], dropouth=drops[4], qrnn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.clip = 25.\n",
    "learner.lr_find(start_lr=1e-5, end_lr=1, linear=False)\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = 2e-3\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = 5e-4\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save(\"lm_qrnn\")\n",
    "learner.save_encoder(\"lm_qrnn_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load(\"lm_qrnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.1, 0.1, 0.05, 0, 0.1])\n",
    "learner = model_data.get_model(\n",
    "    partial(Adam, betas=(0.7, 0.99)),\n",
    "    emb_sz=300, n_hid=500, n_layers=3,\n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2],\n",
    "    dropoute=drops[3], dropouth=drops[4], qrnn=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f196c0840f704eada446dd0b6cd13991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5362/6120 [18:27<02:36,  4.84it/s, loss=18.9]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.clip = 10.\n",
    "learner.lr_find(start_lr=1e-5, end_lr=1, linear=False)\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d5a2d8ac204eea8f9805647498fdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      4.736591   4.668442  \n",
      "    1      4.648549   4.510971                                  \n",
      "    2      4.637241   4.52023                                   \n",
      "    3      4.625277   4.481868                                  \n",
      "    4      4.566185   4.425078                                  \n",
      "    5      4.535305   4.38997                                   \n",
      "    6      4.515515   4.358727                                  \n",
      "    7      4.487952   4.329127                                  \n",
      "    8      4.503434   4.303454                                  \n",
      "    9      4.47837    4.276612                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.276612449269266]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs = 3e-3\n",
    "learner.clip = 10.\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"lm_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2863ff5d8b4e34a75f74504f33a1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      4.471348   4.278106  \n",
      "    1      4.463167   4.287122                                  \n",
      "    2      4.469346   4.297201                                  \n",
      "    3      4.470476   4.296793                                  \n",
      "    4      4.475106   4.289094                                  \n",
      " 38%|███▊      | 9263/24484 [12:49<21:04, 12.04it/s, loss=4.48]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7dab8a925206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_wd_sched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs = 5e-4\n",
    "learner.fit(lrs, 1, wds=1e-7, use_clr=(50, 3), cycle_len=10, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(\"lm_lstm\")\n",
    "learner.save_encoder(\"lm_lstm_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tons of memory...\n",
    "# pred, targ = learner.predict_with_targs(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_iter = iter(trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(tmp_iter)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load(\"lm_lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(24393, 300, padding_idx=0)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(24393, 300, padding_idx=0)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(300, 500)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(500, 500)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(500, 300)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout()\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout()\n",
       "      (1): LockedDropout()\n",
       "      (2): LockedDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=300, out_features=24393, bias=False)\n",
       "    (dropout): LockedDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Character Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/46/c6f9179f73b818d5827202ad1c4a94e371a29473b7f043b736b4dab6b8cd/jieba-0.39.zip (7.3MB)\n",
      "\u001b[K    100% |################################| 7.3MB 1.9MB/s ta 0:00:0111\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Running setup.py bdist_wheel for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/docker/.cache/pip/wheels/c9/c7/63/a9ec0322ccc7c365fd51e475942a82395807186e94f0522243\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.39\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[298, 7, 148, 7074, 226, 2, 42, 870, 6259, 25, 154, 11036, 3299]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = \"德国 是 世界 大国 之一 ， 其 国内 生产总值 以 国际 汇率 计\"\n",
    "tokens = list(map(lambda x: mapping.get(x, 1), texts.split(\" \")))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 24393])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>德国</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>是</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>世界</td>\n",
       "      <td>最</td>\n",
       "      <td>世界</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>大国</td>\n",
       "      <td>第一</td>\n",
       "      <td>最</td>\n",
       "      <td>上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>之一</td>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>，</td>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>其</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>而</td>\n",
       "      <td>但</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>国内</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>主要</td>\n",
       "      <td>地位</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>生产总值</td>\n",
       "      <td>生产总值</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>以</td>\n",
       "      <td>为</td>\n",
       "      <td>是</td>\n",
       "      <td>则</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>国际</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>其</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>汇率</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>货币</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>计</td>\n",
       "      <td>为</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>，</td>\n",
       "      <td>为</td>\n",
       "      <td>。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orig pred_1 pred_2 pred_3\n",
       "0     德国                     \n",
       "1      是      的  <unk>      、\n",
       "2     世界      最     世界  <unk>\n",
       "3     大国     第一      最      上\n",
       "4     之一      。      ，      的\n",
       "5      ，      。      ，      的\n",
       "6      其  <unk>      而      但\n",
       "7     国内  <unk>     主要     地位\n",
       "8   生产总值   生产总值  <unk>      的\n",
       "9      以      为      是      则\n",
       "10    国际  <unk>      1      其\n",
       "11    汇率  <unk>     货币     金融\n",
       "12     计      为      的  <unk>\n",
       "13            ，      为      。"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = np.argsort(logits.data.cpu().numpy(), 1)\n",
    "preds = []\n",
    "for i in range(1, 4):\n",
    "      preds.append(list(map(lambda x: itos[x], sorted_idx[:, -i])))\n",
    "# preds = list(map(lambda x: itos[x], np.argmax(logits.data.cpu().numpy(), 1)))\n",
    "pd.DataFrame({\"orig\": list(texts.split(\" \")) + [\" \"], \n",
    "              \"pred_1\": [\"\"] + preds[0], \"pred_2\": [\"\"] + preds[1], \"pred_3\": [\"\"] + preds[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(texts):\n",
    "    learner.model[0].reset()\n",
    "    tokens = list(map(lambda x: mapping.get(x, 1), texts))\n",
    "    logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "    sorted_idx = np.argsort(logits.data.cpu().numpy(), 1)\n",
    "    preds = []\n",
    "    for i in range(1, 4):\n",
    "          preds.append(list(map(lambda x: itos[x], sorted_idx[:, -i])))\n",
    "    # preds = list(map(lambda x: itos[x], np.argmax(logits.data.cpu().numpy(), 1)))\n",
    "    return pd.DataFrame({\"orig\": [x for x in texts] + [\" \"], \n",
    "                  \"pred_1\": [\"\"] + preds[0], \"pred_2\": [\"\"] + preds[1], \"pred_3\": [\"\"] + preds[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.525 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>现代</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>中国</td>\n",
       "      <td>此</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>印刷</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>社会</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>媒体</td>\n",
       "      <td>的</td>\n",
       "      <td>中</td>\n",
       "      <td>，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>，</td>\n",
       "      <td>中</td>\n",
       "      <td>上</td>\n",
       "      <td>的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>卡通</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>并</td>\n",
       "      <td>以</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>是</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>的</td>\n",
       "      <td>和</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>一种</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>一</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>通常</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>，</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>有</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>幽默</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>一</td>\n",
       "      <td>两</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>色</td>\n",
       "      <td>的</td>\n",
       "      <td>、</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>的</td>\n",
       "      <td>，</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig pred_1 pred_2 pred_3\n",
       "0     在                     \n",
       "1    现代  <unk>     中国      此\n",
       "2    印刷      的  <unk>     社会\n",
       "3    媒体      的      中      ，\n",
       "4     ，      中      上      的\n",
       "5    卡通  <unk>      并      以\n",
       "6     是  <unk>      的      和\n",
       "7    一种  <unk>      一      在\n",
       "8    通常      的  <unk>      ，\n",
       "9     有      的  <unk>      在\n",
       "10   幽默  <unk>      一      两\n",
       "11    色      的      、  <unk>\n",
       "12           的      ，      、"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(list(jieba.cut(\"在现代印刷媒体，卡通是一种通常有幽默色\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>对</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中国</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>此</td>\n",
       "      <td>其</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>与</td>\n",
       "      <td>的</td>\n",
       "      <td>大陆</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>南洋</td>\n",
       "      <td>中国</td>\n",
       "      <td>日本</td>\n",
       "      <td>台湾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>发动</td>\n",
       "      <td>的</td>\n",
       "      <td>地区</td>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>全面</td>\n",
       "      <td>了</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>的</td>\n",
       "      <td>的</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>战争</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>战争</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>攻击</td>\n",
       "      <td>战争</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>。</td>\n",
       "      <td>。</td>\n",
       "      <td>，</td>\n",
       "      <td>；</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1990</td>\n",
       "      <td></td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>在</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>年代</td>\n",
       "      <td>年代</td>\n",
       "      <td>至</td>\n",
       "      <td>年初</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>，</td>\n",
       "      <td>，</td>\n",
       "      <td>初</td>\n",
       "      <td>中期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>中</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>中国</td>\n",
       "      <td>香港</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>日</td>\n",
       "      <td>美</td>\n",
       "      <td>英</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orig pred_1 pred_2 pred_3\n",
       "0      对                     \n",
       "1     中国  <unk>      此      其\n",
       "2      与      的     大陆  <unk>\n",
       "3     南洋     中国     日本     台湾\n",
       "4     发动      的     地区      、\n",
       "5     全面      了      的  <unk>\n",
       "6      的      的  <unk>     战争\n",
       "7     战争  <unk>     攻击     战争\n",
       "8      。      。      ，      ；\n",
       "9   1990         <unk>      在\n",
       "10    年代     年代      至     年初\n",
       "11     ，      ，      初     中期\n",
       "12     中  <unk>     中国     香港\n",
       "13            日      美      英"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(list(jieba.cut(\"对中国与南洋发动全面的战争。1990年代，中\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07845 0.05266 0.04809] 0.00010213052\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十\n",
      "[0.51401 0.11231 0.09117] 0.5140138\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年\n",
      "[0.15643 0.12442 0.10501] 0.124419756\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后\n",
      "[0.26499 0.11463 0.04732] 0.00067782955\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了\n",
      "[0.03007 0.03001 0.0246 ] 0.006189509\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定\n",
      "[0.0592  0.03512 0.03437] 0.0018525779\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期\n",
      "[0.13655 0.0554  0.04897] 7.03813e-05\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂\n",
      "[0.51255 0.07831 0.03414] 0.51254594\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的\n",
      "[0.2042  0.07072 0.02253] 0.009841645\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治\n",
      "[0.07701 0.0682  0.06336] 0.0034091698\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候\n",
      "[0.63012 0.13928 0.05908] 0.6301237\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，\n",
      "[0.06032 0.03049 0.02442] 6.559916e-06\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间\n",
      "[0.06304 0.02615 0.02359] 0.0003391894\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入\n",
      "[0.25861 0.09737 0.01924] 0.008255953\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国\n",
      "[0.39079 0.07095 0.03851] 0.0011106768\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被\n",
      "[0.07243 0.0329  0.03154] 0.032899868\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国\n",
      "[0.23032 0.07711 0.06045] 0.06045246\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的\n",
      "[0.06861 0.04334 0.02497] 0.0015600701\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购\n",
      "[0.27706 0.25406 0.05681] 0.27706438\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。\n",
      "[0.2079  0.07413 0.04871] 0.0017104413\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国\n",
      "[0.34885 0.06222 0.03918] 0.062221136\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国在\n",
      "[0.07509 0.04045 0.0196 ] 0.007349524\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国在大陆\n",
      "[0.15731 0.03595 0.02797] 0.006967958\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国在大陆被\n",
      "[0.09702 0.06348 0.05437] 0.0012042096\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国在大陆被以\n",
      "[0.16684 0.0979  0.05061] 4.4778808e-05\n",
      "德国是<unk>之一，其国内生产总值以国际汇率为主，十年后为了稳定长期复杂的政治气候，瞬间卷入中国被中国的收购。中华民国在大陆被以六十\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_tokens(texts, seg=True):\n",
    "    if seg:\n",
    "        texts = list(jieba.cut(texts))\n",
    "    return list(map(lambda x: mapping.get(x, 1), texts))\n",
    "\n",
    "def generate_text(tokens,N=25):    \n",
    "    preds = []          \n",
    "    for i in range(N):   \n",
    "        learner.model[0].reset()          \n",
    "        logits, _, _ = learner.model(T(tokens).unsqueeze(1))\n",
    "        probs = F.softmax(logits).data.cpu().numpy()[-1, :]\n",
    "        candidates = np.argsort(probs)[::-1]\n",
    "        while True:\n",
    "            candidate = np.random.choice(candidates, p=probs[candidates])\n",
    "            if candidate > 1:\n",
    "                print(probs[candidates][:3], probs[candidate])\n",
    "                preds.append(candidate)\n",
    "                break\n",
    "        # for candidate in candidates:\n",
    "        #     if candidate > 1 and ord(itos[candidate]) > 255 and (random.random() < probs[candidate] or probs[candidate] < 0.2):\n",
    "        #         print(probs[candidate])\n",
    "        #         preds.append(candidate)\n",
    "        #         break\n",
    "        # tokens  = [preds[-1]]# \n",
    "        tokens.append(preds[-1])\n",
    "        # tokens = [:1]\n",
    "        print(\"\".join([itos[x] for x in tokens])) \n",
    "    \n",
    "generate_text(get_tokens(\"德国是世界大国之一，其国内生产总值以国际汇率为主，\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07781 0.04344 0.0422 ] 8.371915e-05\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排\n",
      "[0.5791  0.04529 0.04371] 0.5790994\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在\n",
      "[0.08871 0.06025 0.05663] 0.043066986\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二\n",
      "[0.57436 0.1548  0.06422] 0.5743636\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位\n",
      "[0.49874 0.34714 0.03853] 0.49873507\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。\n",
      "[0.1852  0.07714 0.06073] 4.1774725e-05\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部\n",
      "[0.07366 0.06926 0.05097] 0.07365563\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在\n",
      "[0.03813 0.02648 0.02014] 0.00086606364\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19\n",
      "[0.92585 0.02273 0.00977] 0.925852\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪\n",
      "[0.14921 0.0954  0.07334] 0.020954467\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期\n",
      "[0.11468 0.06735 0.06547] 0.067347266\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，\n",
      "[0.06228 0.0396  0.0289 ] 0.062281303\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在\n",
      "[0.10091 0.04536 0.04307] 0.011501491\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾\n",
      "[0.10793 0.03512 0.03398] 1.0227723e-05\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──\n",
      "[0.22042 0.04707 0.02378] 2.3880955e-05\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使\n",
      "[0.12824 0.11571 0.06743] 1.8295434e-07\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华\n",
      "[0.12337 0.0639  0.06224] 0.002289299\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立\n",
      "[0.24083 0.08452 0.05792] 0.24083252\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了\n",
      "[0.12266 0.07239 0.06264] 2.118049e-06\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达\n",
      "[0.14208 0.06255 0.05189] 0.062548995\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司\n",
      "[0.50591 0.1835  0.08295] 0.5059064\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司，\n",
      "[0.16037 0.04011 0.03656] 0.1603672\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司，并\n",
      "[0.11635 0.11097 0.04832] 0.0066201636\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司，并对\n",
      "[0.10089 0.09993 0.0907 ] 0.0804026\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司，并对此\n",
      "[0.12113 0.03524 0.0305 ] 0.12112837\n",
      "德国是世界大国之一，其国内生产总值以国际汇率为主，排在第二位。经济部在19世纪后期，在台湾──致使安华建立了万达公司，并对此进行\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"德国 是 世界 大国 之一 ， 其 国内 生产 总 值 以 国际 汇率 为主 ，\".split(\" \"), seg=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57148 0.10214 0.08893] 0.10213592\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，\n",
      "[0.12241 0.04842 0.02696] 0.00512519\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被\n",
      "[0.16758 0.11191 0.06359] 0.02920835\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人\n",
      "[0.27767 0.09662 0.06675] 0.0006173651\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑\n",
      "[0.20633 0.08822 0.06203] 0.008166621\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，\n",
      "[0.14941 0.03693 0.03217] 0.002003036\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指\n",
      "[0.24453 0.09932 0.02587] 0.005567843\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为\n",
      "[0.31994 0.05797 0.03811] 0.0013306263\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时\n",
      "[0.22526 0.11243 0.0357 ] 0.00038319558\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的\n",
      "[0.22117 0.07134 0.01125] 0.00091244903\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他\n",
      "[0.17724 0.03044 0.0282 ] 0.0008020848\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「\n",
      "[0.38756 0.00886 0.00842] 0.000650396\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们\n",
      "[0.32084 0.17149 0.1125 ] 0.17148939\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的\n",
      "[0.36169 0.01851 0.01332] 0.00017412976\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像\n",
      "[0.38612 0.11171 0.0904 ] 0.00018850392\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/\n",
      "[0.10611 0.01873 0.01766] 0.00054056145\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理\n",
      "[0.11135 0.07953 0.05507] 0.010589225\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式\n",
      "[0.57668 0.10968 0.07248] 0.57667893\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」\n",
      "[0.4858  0.23323 0.05428] 0.23323293\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，\n",
      "[0.06557 0.05952 0.03407] 0.01981238\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在\n",
      "[0.13992 0.01295 0.01277] 0.0036469845\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他\n",
      "[0.36201 0.05351 0.03515] 0.3620107\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的\n",
      "[0.12995 0.10031 0.04044] 0.00022794218\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签\n",
      "[0.259   0.15516 0.11674] 0.00017568417\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签宣传\n",
      "[0.18719 0.10796 0.04519] 0.010544763\n",
      "在现代印刷媒体，卡通是<unk>通常有幽默色，被人笑，指为当时有的其他「他们的图像/管理模式」，在他的标签宣传方面\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"在现代印刷媒体，卡通是一种通常有幽默色\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08504 0.06818 0.06074] 0.02500637\n",
      "在现代印刷媒体，第9\n",
      "[0.13459 0.06125 0.04664] 0.030996583\n",
      "在现代印刷媒体，第9卷\n",
      "[0.0969  0.08753 0.0629 ] 0.006358325\n",
      "在现代印刷媒体，第9卷由\n",
      "[0.35964 0.03145 0.01448] 1.7974633e-05\n",
      "在现代印刷媒体，第9卷由化工\n",
      "[0.16731 0.07625 0.03606] 0.036059707\n",
      "在现代印刷媒体，第9卷由化工专家\n",
      "[0.41738 0.02947 0.02199] 0.00011674958\n",
      "在现代印刷媒体，第9卷由化工专家审核\n",
      "[0.48608 0.20592 0.02552] 0.01952854\n",
      "在现代印刷媒体，第9卷由化工专家审核后\n",
      "[0.38415 0.03064 0.02981] 0.021977516\n",
      "在现代印刷媒体，第9卷由化工专家审核后才\n",
      "[0.08799 0.05267 0.04986] 0.00034258587\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施\n",
      "[0.53146 0.27191 0.02317] 0.53145814\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。\n",
      "[0.27509 0.11845 0.03967] 0.27509338\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。\n",
      "[0.34999 0.0422  0.03589] 0.0006392756\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国\n",
      "[0.09464 0.06684 0.02582] 2.4371655e-05\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HD\n",
      "[0.46511 0.03778 0.02301] 0.0020391832\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF\n",
      "[0.19441 0.13165 0.08699] 0.00014141893\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.\n",
      "[0.30597 0.12904 0.02071] 0.1290385\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是\n",
      "[0.14171 0.12552 0.10233] 0.00020001286\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚\n",
      "[0.16397 0.06741 0.0294 ] 7.9754244e-07\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年\n",
      "[0.22977 0.04292 0.02017] 0.013750514\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立\n",
      "[0.87006 0.02853 0.01924] 0.8700575\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的\n",
      "[0.11482 0.08104 0.05644] 0.00043080564\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的计划\n",
      "[0.30852 0.20168 0.08991] 0.08990732\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的计划中\n",
      "[0.4306  0.08428 0.06778] 0.003199747\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的计划中第\n",
      "[0.12841 0.10604 0.08102] 0.02709077\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的计划中第9\n",
      "[0.43928 0.14227 0.06992] 0.4392832\n",
      "在现代印刷媒体，第9卷由化工专家审核后才实施。法国HDF.是利比亚该年成立的计划中第9个\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"在现代印刷媒体，第\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18456 0.08527 0.05694] 0.18455671\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。\n",
      "[0.34377 0.0461  0.03459] 0.00032342097\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九\n",
      "[0.15202 0.05443 0.04422] 0.00053708686\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书\n",
      "[0.12713 0.10896 0.06299] 1.5963882e-05\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加\n",
      "[0.59347 0.05559 0.03777] 0.59346837\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了\n",
      "[0.16312 0.06443 0.03932] 0.0021941084\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七\n",
      "[0.30051 0.09204 0.06165] 0.30051193\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个\n",
      "[0.10479 0.03752 0.03398] 0.0014496067\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级\n",
      "[0.24135 0.14488 0.07724] 0.14487728\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生\n",
      "[0.22152 0.13946 0.04149] 0.020714818\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和\n",
      "[0.246   0.07621 0.06824] 9.907548e-07\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效\n",
      "[0.21746 0.07187 0.04898] 0.0004736853\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与\n",
      "[0.17607 0.17385 0.03965] 0.016922804\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校\n",
      "[0.64427 0.04583 0.03099] 0.64427274\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的\n",
      "[0.44333 0.03265 0.01503] 0.005023754\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“\n",
      "[0.28187 0.03744 0.00953] 8.4614294e-05\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性\n",
      "[0.18379 0.08119 0.02939] 0.0008598249\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力\n",
      "[0.41058 0.03296 0.03132] 0.029435774\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育\n",
      "[0.75692 0.01829 0.00867] 0.7569225\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”\n",
      "[0.37951 0.20422 0.06638] 0.00020366868\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各\n",
      "[0.36504 0.06641 0.05845] 0.3650389\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各一\n",
      "[0.1503  0.1122  0.10113] 0.0001932059\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各一由\n",
      "[0.09814 0.09236 0.05178] 0.025085775\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各一由学校\n",
      "[0.06223 0.05513 0.0367 ] 0.05513186\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各一由学校学生\n",
      "[0.10673 0.03534 0.03389] 0.033257656\n",
      "日本后来成为<unk>的轴心国之一，对中国与南洋发动全面的战争。九书增加了七个年级学生和成效参与学校的“性能力教育”各一由学校学生学习\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"日本后来成为第二次世界大战的轴心国之一，对中国与南洋发动全面的战争。\"))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46438 0.176   0.05057] 0.0505674\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的\n",
      "[0.2676  0.05387 0.02256] 0.00027404854\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义\n",
      "[0.1385  0.13762 0.07186] 0.07185615\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度\n",
      "[0.42288 0.39987 0.03587] 0.4228803\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。\n",
      "[0.11405 0.07251 0.04429] 0.0009164135\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被\n",
      "[0.18877 0.07216 0.06751] 0.00087133015\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「\n",
      "[0.26014 0.04209 0.01235] 0.042087898\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本\n",
      "[0.23112 0.16531 0.05584] 0.16530591\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」\n",
      "[0.09888 0.04346 0.04307] 0.015173969\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与\n",
      "[0.37394 0.19135 0.07641] 0.19135265\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「\n",
      "[0.14491 0.14153 0.03498] 0.0003742945\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古\n",
      "[0.2703  0.15925 0.12344] 0.0015813209\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明\n",
      "[0.7816  0.05917 0.02   ] 0.7815963\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」\n",
      "[0.10799 0.08628 0.04781] 0.010835725\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为\n",
      "[0.16001 0.10412 0.05435] 0.004529482\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于\n",
      "[0.17195 0.08897 0.03151] 4.410098e-06\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏\n",
      "[0.20502 0.17167 0.04348] 0.043481022\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，\n",
      "[0.07669 0.05146 0.04912] 0.0032783335\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且\n",
      "[0.06899 0.04956 0.04263] 0.0010967606\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全\n",
      "[0.08728 0.0789  0.06878] 0.0020838408\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将\n",
      "[0.11116 0.0693  0.04654] 0.008857515\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将台湾\n",
      "[0.21935 0.06189 0.03514] 0.21935466\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将台湾的\n",
      "[0.13529 0.04841 0.04239] 0.0003403496\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将台湾的成为\n",
      "[0.14663 0.0654  0.05384] 0.0015773344\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将台湾的成为他\n",
      "[0.61905 0.03199 0.02953] 0.6190462\n",
      "传说日本于公元前<unk>年2月11日建国，在公元4世纪出现<unk>统一政权，并于<unk><unk>确立了天皇的中央集权体制。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等<unk>文化引进的事物，开始派<unk>今日<unk>的文化基础。12世纪后的六百年间，日本由<unk>阶级创建的<unk>幕府及军事<unk>实际掌权，期间包括了政治<unk>的南北朝与战国的资本主义制度。被「日本」与「蒙古文明」视为属于节奏，而且完全将台湾的成为他的\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"传说日本于公元前660年2月11日建国，在公元4世纪出现首个统一政权，并于大化改新中确立了天皇的中央集权体制\"\n",
    "                         \"。至平安时代结束前，日本透过文字、宗教、艺术、政治制度等从汉文化引进的事物，开始派生出今日为人所知的文化基\"\n",
    "                         \"础。12世纪后的六百年间，日本由武家阶级创建的数个幕府及军事强人政权实际掌权，期间包括了政治纷乱的南北朝与\"\n",
    "                         \"战国\"))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10046 0.07854 0.04845] 0.012627744\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足\n",
      "[0.77163 0.03732 0.01321] 0.0028353613\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一\n",
      "[0.20588 0.15337 0.12317] 0.015922893\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍\n",
      "[0.74628 0.03113 0.02749] 0.7462765\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，\n",
      "[0.08947 0.08114 0.03271] 0.010085421\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将\n",
      "[0.35467 0.04349 0.02761] 0.35466844\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会\n",
      "[0.04675 0.04592 0.0306 ] 0.0055490164\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发\n",
      "[0.10218 0.03045 0.02726] 0.018784117\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国\n",
      "[0.19296 0.10781 0.05721] 0.19296469\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆\n",
      "[0.24402 0.04013 0.03667] 0.0010175591\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部\n",
      "[0.21184 0.07667 0.04107] 0.0042955666\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民\n",
      "[0.32462 0.08561 0.05317] 0.046288818\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对\n",
      "[0.11763 0.06627 0.02251] 0.00028754634\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人\n",
      "[0.34439 0.05825 0.02364] 0.00029022482\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族\n",
      "[0.36175 0.0474  0.03023] 0.0037873136\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性\n",
      "[0.57036 0.046   0.02078] 0.57036227\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的\n",
      "[0.25393 0.13475 0.0744 ] 0.2539349\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视\n",
      "[0.42323 0.31309 0.06313] 0.42323226\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。\n",
      "[0.17086 0.05711 0.03346] 0.0020736337\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些\n",
      "[0.05088 0.04463 0.03627] 0.00012163013\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜\n",
      "[0.07308 0.05199 0.04438] 0.010861337\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜经济\n",
      "[0.10412 0.0355  0.02963] 0.024375234\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜经济和\n",
      "[0.23675 0.17937 0.06727] 0.23675366\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜经济和社会\n",
      "[0.0735  0.05717 0.04504] 0.00066046935\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜经济和社会实际\n",
      "[0.13445 0.11014 0.10011] 0.13445172\n",
      "特朗普政府以为<unk>关税<unk>中国屈服，这种策略肯定会<unk>。如果就业和财富不足一倍，将会引发中国大陆中部农民对黑人汉族女性的歧视。这些朝鲜经济和社会实际生活\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"特朗普政府以为加征关税会令中国屈服，这种策略肯定会适得其反。如果就业和财富\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53561 0.26385 0.0271 ] 0.5356056\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。\n",
      "[0.29567 0.10711 0.03843] 0.02079274\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而\n",
      "[0.15756 0.15462 0.03683] 0.036831804\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港\n",
      "[0.1532  0.0645  0.03328] 0.0023465073\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区\n",
      "[0.69043 0.03445 0.01556] 0.69043\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府\n",
      "[0.12213 0.11858 0.08772] 0.0035020853\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并\n",
      "[0.28014 0.22292 0.18848] 0.18848261\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不\n",
      "[0.11025 0.07209 0.04711] 0.010015272\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在\n",
      "[0.10584 0.07783 0.07556] 0.07556277\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港\n",
      "[0.12051 0.092   0.07096] 0.002788846\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建\n",
      "[0.13735 0.08461 0.05968] 0.036508825\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个\n",
      "[0.11818 0.07343 0.0734 ] 0.001885635\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际\n",
      "[0.18994 0.0586  0.05557] 0.055574343\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准\n",
      "[0.31795 0.14636 0.08451] 5.0799565e-07\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属\n",
      "[0.10758 0.10735 0.08584] 0.10734904\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，\n",
      "[0.1731  0.04559 0.03809] 0.006493946\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港\n",
      "[0.14295 0.08216 0.06288] 0.00017407161\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人\n",
      "[0.08555 0.04424 0.04263] 0.02760776\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只\n",
      "[0.14184 0.08687 0.08565] 0.1418418\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会\n",
      "[0.2248  0.03786 0.03615] 2.8692739e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批\n",
      "[0.3959  0.05082 0.03927] 0.050823856\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批到\n",
      "[0.15201 0.13201 0.01448] 5.8151463e-06\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批到承办\n",
      "[0.08913 0.05069 0.03771] 0.0002653321\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批到承办墨尔本\n",
      "[0.17561 0.1569  0.07602] 0.007040453\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批到承办墨尔本会议\n",
      "[0.35582 0.15062 0.14204] 0.35581943\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地。而香港特区政府并不在香港兴建一个国际标准部属，香港艺人只会批到承办墨尔本会议的\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Instagram上备受欢迎的拍照地\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52148 0.36864 0.0094 ] 0.00017321824\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会\n",
      "[0.06992 0.0674  0.06143] 0.06991685\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被\n",
      "[0.06367 0.0596  0.05485] 0.00084782025\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解\n",
      "[0.44276 0.12413 0.11418] 0.008236747\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在\n",
      "[0.11986 0.05162 0.02879] 9.1968206e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义\n",
      "[0.40945 0.22531 0.0814 ] 0.00082443195\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国\n",
      "[0.20361 0.07379 0.05724] 0.00017054846\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入\n",
      "[0.15006 0.08147 0.05248] 0.00031420393\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元\n",
      "[0.29546 0.07231 0.06112] 0.29545942\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的\n",
      "[0.12334 0.04321 0.04205] 0.014108545\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程\n",
      "[0.8221  0.04465 0.0442 ] 0.8220993\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中\n",
      "[0.47163 0.17247 0.02483] 0.00033108244\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说\n",
      "[0.16258 0.15353 0.1196 ] 0.16257909\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出\n",
      "[0.08942 0.08106 0.06787] 0.059044205\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，\n",
      "[0.06466 0.03869 0.03675] 1.1690971e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆\n",
      "[0.21619 0.0457  0.03456] 0.013961536\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被\n",
      "[0.0694  0.04678 0.04396] 0.0004751753\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁\n",
      "[0.44396 0.1267  0.04891] 0.03390415\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于\n",
      "[0.20028 0.04144 0.01832] 0.00060757203\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后\n",
      "[0.11846 0.06367 0.05401] 0.00016783657\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆\n",
      "[0.15495 0.152   0.12304] 0.1230387\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆，\n",
      "[0.06528 0.04725 0.0266 ] 0.026603179\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆，并\n",
      "[0.08958 0.0524  0.03893] 0.052398678\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆，并被\n",
      "[0.08487 0.06282 0.03587] 0.0046208436\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆，并被批评\n",
      "[0.32425 0.19903 0.0328 ] 0.008889268\n",
      "香港有半数<unk>在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，<unk>一个与<unk>中的香港不同的景象会被理解在广义中国入元的过程中说出，图书馆被锁于皇后公馆，并被批评并\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Instagram上备受欢迎的拍照地，\"\n",
    "                         \"呈现出一个与天际线中的香港不同的景象\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22248 0.14943 0.14735] 8.31102e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台\n",
      "[0.41727 0.11    0.082  ] 0.081996776\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，\n",
      "[0.0625  0.04938 0.03701] 5.9475176e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕\n",
      "[0.19647 0.15026 0.05191] 2.4764933e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士\n",
      "[0.11231 0.11133 0.02376] 0.012419443\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及\n",
      "[0.05653 0.04455 0.04266] 0.0012519377\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球\n",
      "[0.13554 0.13303 0.03929] 0.133033\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地\n",
      "[0.51941 0.03426 0.01393] 0.51940936\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的\n",
      "[0.13492 0.01441 0.01269] 0.0010259144\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋\n",
      "[0.15255 0.02915 0.02531] 0.0001460682\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云\n",
      "[0.14645 0.05912 0.0361 ] 0.0022190318\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料\n",
      "[0.19616 0.09811 0.07649] 0.19615789\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，\n",
      "[0.04253 0.03291 0.02743] 0.0003579836\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作\n",
      "[0.14703 0.12852 0.06125] 0.14703265\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出\n",
      "[0.09691 0.07927 0.07672] 0.0969143\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一\n",
      "[0.16587 0.0878  0.08759] 0.08758752\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列\n",
      "[0.30372 0.09754 0.01178] 5.0934064e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝\n",
      "[0.2058  0.05131 0.02812] 0.005172723\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山\n",
      "[0.1692  0.07579 0.04626] 3.197875e-05\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人\n",
      "[0.20168 0.18955 0.16935] 0.16934684\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。\n",
      "[0.27448 0.10077 0.0435 ] 0.2744774\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。\n",
      "[0.31947 0.04728 0.02981] 0.00017072099\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。比\n",
      "[0.44897 0.17902 0.01218] 0.1790214\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。比起\n",
      "[0.14614 0.03438 0.0165 ] 0.00045922684\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。比起澳洲\n",
      "[0.13824 0.09083 0.08832] 0.13823605\n",
      "香港有半数<unk>在公屋，如今这里意外成为<unk>天文台，围绕瑞士及全球各地的海洋云资料，制作出一系列蓝山太空人。比起澳洲的\n"
     ]
    }
   ],
   "source": [
    "generate_text(get_tokens(\"香港有半数人住在公屋，如今这里意外成为Insta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
